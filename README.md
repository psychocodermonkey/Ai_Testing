# AI Testing playground

This is a simple project to test and experiment with different AI models. Includes a easy method to pull down pre-trained models from Hugging Face.

`.gitignore` is enforced in the `/models/` directory, so you can safely clone models without worrying about them being pushed back to github.

More to come as it gets developed!

## A Python Script with functions for simplifying model handling - [Ubiquitous.py](Ubiquitous.py)

### Overview

This file provides a set of Python functions designed to simplify and streamline various tasks related to machine learning model handling, particularly those involving Hugging Face repositories. The primary goal is to make it easier to download, manage, and utilize models from Hugging Face's vast library without the need for reinvention of the wheel.

### Key Functions in Ubiquitous.py

#### 1. `getModelDir()`

- **Purpose**: This function generates a directory where models will be stored. It also ensures that a `.gitignore` file is created within this directory to prevent unwanted files from being tracked by Git.
- **Usage**: Call `getModelDir()` to get the path to the model directory, which can then be used for downloading and storing models.

#### 2. `getOutputDir()`

- **Purpose**: This function generates a directory where output generated by scripts will be stored. Similar to `getModelDir()`, it ensures that a `.gitignore` file is created within this directory to maintain the locality of the data within it. This file will have the large model files and does not need to be synced to GitHub.
- **Usage**: Call `getOutputDir()` to get the path for saving script outputs, which can then be easily accessed for review or further processing.

#### 3. `getModel(repoID, fileName, override)`

- **Purpose**: This function downloads a model from Hugging Face if it does not already exist locally. It supports an optional parameter to force redownloading of the model even if it exists.
- **Usage**: Call `getModel(repoID, fileName, override)` with the repository ID and filename of the model you want to download. The function will return the path to the model or `None` if there's a problem.

#### 4. `hfLogin()`

- **Purpose**: This function logs in to Hugging Face using an API token stored in an environment file. It checks for the presence of the token and attempts to log in accordingly.
- **Usage**: Call `hfLogin()` to ensure that your Hugging Face credentials are available for use with model downloading functions.

#### 5. `loadPrompt(promptFile)`

- **Purpose**: This function parses a prompt file to extract sections such as the main prompt, exclusion prompts, refine prompts, and exclude refines.
- **Usage**: Call `loadPrompt(promptFile)` with the path to your prompt file to get structured data for use in generating text or images based on specific instructions.

#### 6. `genPromptString(lines)`

- **Purpose**: This helper function converts a list of strings into a single string separated by commas, suitable for feeding directly into model inputs.
- **Usage**: Use this function within your script to convert lists of prompts or exclusions into the format expected by Hugging Face models.

## Image AI Model shell for Diffusers - [genImage-diff.py](genImage-diff.py)

A local, dict-driven image generation shell built on **Hugging Face Diffusers**.
Designed for fast experimentation across multiple txt2img and img2img pipelines, with model behavior centralized in a single `MODELS` registry.

---

### What it does

This script runs up to two stages:

1. **Text → Image (txt2img)**
   Generates an initial image from the prompt file.

2. **Image → Image refinement (img2img)** *(optional)*
   Refines the generated image (or a user-supplied input image) using a second prompt stage.

Final output is saved as a timestamped PNG:

```bash
<promptFileStem>-YYYYMMDD-HHMMSS.png
```

---

### Key features

- **One script, many models**
  All model behavior lives in `MODELS` (repo IDs, pipelines, dtype, offload, per-stage parameters).

- **Hardware-aware**
  Uses `mps` on Apple Silicon if available, otherwise falls back to `cpu`.

- **Optional gated model handling**
  Logs into Hugging Face and fails cleanly on `GatedRepoError`.

- **Disk-awareness for models**
  `--list-models` shows configured models and highlights those not cached in `MODEL_DIR`.

- **Two-stage prompt design**
  Base prompt + optional refine prompt.

- **Input image mode**
  `--input-image` skips txt2img and can drive refinement directly.

---

### Prompt file format

Prompt files are parsed by `loadPrompt()` from `Ubiquitous` module noted above.
The script looks for the following keys. `prompt` is the only hard required key.

#### Base generation keys

- `prompt`
  Main prompt lines.

- `exclude` *(optional)*
  Negative prompt lines.

#### Refinement keys (optional)

- `refine prompt`
  Prompt lines for img2img refinement.

- `refine exclude` *(optional)*
  Negative prompt lines for refinement.

Each section is converted into a single string using `genPromptString()`.

#### Behavior notes

- If `refine prompt` is **missing or empty**, the refine stage is skipped.
- If `--input-image` is supplied and `refine prompt` is missing, the script **falls back to the base prompt** so img2img still runs.
- Negative prompt handling is model-driven via `negativePromptMode`:
  - `normal` — include negative prompt if provided
  - `empty` — pass `negative_prompt=""`
  - `omit` — do not pass a negative prompt argument at all
- Comments are allowed using `#`, `//`, or `;` and must be at the beginning of the line.

#### Sample prompt file

```prompt
[prompt]
A anthropomorphic cyberpunk gorilla wearing a leather hooded bomber jacket,
judgy expression,
sitting and using a futuristic computer,
chunky mechanicak keyboard,
multiple computer displays,
programming code on the displays,
high-detailed cyberpunk workstation setting.

[exclude]
human-like facial features
realistic skin texture
ears, nose, mouth, eyebrows
; emotional expressions
hair or fur patterns that do not contribute to the cyberpunk aesthetic

[refine prompt]
judgy expression
code on screens
orange accents on clothing
orange accents on computer
neon orange streaks in fur
high-detail fur, clothing, and computers
code on displays
```

---

### Usage

#### Basic generation (txt2img)

```bash
python genImage-diff.py description.prompt
```

#### Select a model

```bash
python genImage-diff.py description.prompt --model sd3.5-large
```

#### Verbose logging

```bash
python genImage-diff.py description.prompt --model sd3.5-medium --verbose
```

#### Refine an existing image

```bash
python genImage-diff.py refine.prompt \
  --input-image output/previous.png \
  --model sd3.5-medium
```

#### List configured models and cache status

```bash
python genImage-diff.py --list-models
```

---

### Models

Models are defined in the `MODELS` dictionary. Each entry controls:

- `repo` — Hugging Face model repo for txt2img
- `txtPipeline` — Diffusers pipeline class for txt2img
- `imgPipeline` — Diffusers pipeline class for img2img (optional)
- `imgRepo` — repo for img2img pipeline (optional; defaults to `repo`)
- `dtype` — torch dtype used for inference
- `useCpuOffload` — enable `enable_model_cpu_offload()`
- `txt2img` — inference steps, CFG scale, resolution, token limits
- `img2img` — refinement strength, steps, CFG scale, token limits

#### Adding a new model

1. Import the required pipeline class in the Diffusers import block.
2. Add a new entry to `MODELS` with:
   - `repo`
   - `txtPipeline`
   - `dtype`
   - `txt2img` settings
3. If refinement is supported, also add:
   - `imgPipeline`
   - `img2img` settings
   - optional `imgRepo` if refinement uses a different checkpoint

No CLI changes are required.

---

### Output

The output filename is generated automatically:

```bash
OUTPUT_DIR / "<promptFileStem>-YYYYMMDD-HHMMSS.png"
```

Only the final image is saved:

- refined image if refinement ran
- otherwise the base txt2img image
- or the input image if no refinement was performed

---

### Common failure modes

- **Access denied / gated repo**
  You do not have access to the model. Visit the model page, request or accept access, then rerun.
  - Account `auth key` is stored `.env` file at project root with the key name `HF_TOKEN`.

- **Out of memory**
  Reduce resolution or inference steps, enable CPU offload, or use a smaller model.

- **No refinement performed**
  Either `refine prompt` is missing, or the selected model does not define an `imgPipeline`.

---

## License

Copyright (c) 2026 Andrew Dixon
Licensed under the **GNU Lesser General Public License v2.1**.
See the [`LICENSE`](LICENSE) file at the project root.
